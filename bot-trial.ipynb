{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse# %%\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.alert import Alert\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import csv\n",
    "import os\n",
    "import requests\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from datetime import datetime\n",
    "import os\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import csv\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "import openpyxl\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import json\n",
    "from urllib.parse import quote\n",
    "from lxml import etree\n",
    "import json\n",
    "# from openai import OpenAI\n",
    "import json\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n",
    "# import cloudscraper\n",
    "# from bs4 import BeautifulSoup\n",
    "from lxml import html as html_parser\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# loading data from .env file\n",
    "from dotenv import load_dotenv\n",
    "import pyautogui\n",
    "\n",
    "# import data combinations\n",
    "from term_life_data import *\n",
    "# from whole_life_data import *\n",
    "# from endowment_products_data import *\n",
    "\n",
    "def get_driver():\n",
    "    options = Options()\n",
    "    # options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9224\")\n",
    "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    # options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    # Enable headless mode  \n",
    "    # options.add_argument(\"--headless=new\")\n",
    "    # options.add_argument(\"--disable-gpu\")\n",
    "    # options.add_argument(\"--no-sandbox\")\n",
    "    # options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    # open specific chrome proofile\n",
    "    profile_path=os.path.join(os.getcwd(),\"profile\")\n",
    "    options.add_argument(f\"user-data-dir={profile_path}\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.199 Safari/537.36\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(f\"--log-level=3\")\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    action = ActionChains(driver)\n",
    "    return driver, action\n",
    "\n",
    "\n",
    "def switch_to_window(url_part,driver):\n",
    "    for handle in driver.window_handles:\n",
    "        driver.switch_to.window(handle)\n",
    "        if url_part in driver.current_url:\n",
    "            break\n",
    "\n",
    "driver,action= get_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "class TermLifeAutomation:\n",
    "    def __init__(self, search_data):\n",
    "        self.search_data = search_data\n",
    "\n",
    "    def do_search(self):\n",
    "        print(\"Setting search options for Whole Life products\")\n",
    "        self.search_term_life()\n",
    "        print(\"Searching is done...\")\n",
    "\n",
    "    def filter_specific_providers(self):        \n",
    "        # select only specific providers\n",
    "        providers_selectors = [\n",
    "            '[title=\"China Taiping Insurance (Singapore) Pte. Ltd.\"]',\n",
    "            '[title=\"Manulife (Singapore) Pte. Ltd.\"]',\n",
    "            '[title=\"Tokio Marine Life Insurance Singapore Ltd\"]',\n",
    "            '[title=\"China Life Insurance (Singapore) Pte. Ltd.\"]',\n",
    "            '[title=\"Income Insurance Limited\"]',\n",
    "            '[title=\"Singapore Life Ltd.\"]'\n",
    "        ]\n",
    "\n",
    "        # first unchecking the box\n",
    "        uncheck_all = self.wait_element(By.CSS_SELECTOR, '[id=\"AllInsurersCHK\"]', 20)\n",
    "        uncheck_all.click()\n",
    "\n",
    "        self.wait_element(By.CSS_SELECTOR, '[class=\"search-head\"]', 20).click()\n",
    "\n",
    "        for provider_selector in providers_selectors:\n",
    "            ele = self.wait_element(using=By.CSS_SELECTOR, css_code=provider_selector, timeout=2)        \n",
    "            if ele:\n",
    "                checkbox = ele.find_element(By.XPATH, \"..//input[@type='checkbox']\")\n",
    "                checkbox.click()\n",
    "\n",
    "    def search_term_life(self):\n",
    "        self.get_driver_with_retry()\n",
    "        # clicking on specific products type section\n",
    "        self.wait_element(By.XPATH, '//label[contains(text(),\"Whole Life products\")]', 20).click()\n",
    "        \n",
    "        self.wait_element(By.CSS_SELECTOR, '[data-id=\"non-bips\"]', 20).click()\n",
    "\n",
    "        # filling the date box\n",
    "        dob_box = self.wait_element(By.CSS_SELECTOR, '[name=\"dob\"]', 20)\n",
    "        dob_box.clear()\n",
    "        # calculating the dob based on age\n",
    "        dob = datetime.now().year - self.search_data[\"age\"]\n",
    "        dob_box.send_keys(f\"01/01/{dob}\")\n",
    "\n",
    "        # filling gender\n",
    "        self.wait_element(By.CSS_SELECTOR, f'[data-id=\"{self.search_data[\"gender\"]}\"]', 20).click()\n",
    "\n",
    "        # clicking smoker `yes`\n",
    "        self.wait_element(By.CSS_SELECTOR, f'[data-id=\"{self.search_data[\"smoker\"]}\"]', 20).click()\n",
    "\n",
    "        # selecting premium term\n",
    "        premium_term_term_ele = self.wait_element(By.CSS_SELECTOR, '.premiumTermNonDcips a.select2-choice', 20)\n",
    "        premium_term_term_ele.click()\n",
    "        time.sleep(0.2)\n",
    "        print(\"coverage term text: \", self.search_data)\n",
    "        premium_term_text = self.search_data[\"premium_term\"]\n",
    "\n",
    "        option = self.wait_element(By.XPATH, f'//div[contains(text(),\"{premium_term_text}\")]', 20)\n",
    "        option.click()\n",
    "\n",
    "        # selecting sum assured\n",
    "        sum_assured_text = self.search_data[\"sum_assured\"]\n",
    "        sum_assured_ele = self.wait_element(By.CSS_SELECTOR, '.SANonDCIPWLSingle a.select2-choice', 20)\n",
    "        sum_assured_ele.click()\n",
    "        time.sleep(0.2)\n",
    "        option = self.wait_element(By.XPATH, f'//div[contains(text(),\"{sum_assured_text}\")]', 20)\n",
    "        option.click()\n",
    "\n",
    "        # clicking on critical illness button\n",
    "        self.wait_element(By.CSS_SELECTOR, f'#cretical-ill [data-id=\"{self.search_data[\"critical_illness\"]}\"]', 20).click()\n",
    "\n",
    "        # clicking on sort A-Z button\n",
    "        sorting_ele = self.wait_element(By.CSS_SELECTOR, '.sortWLGroup a.select2-choice', 20)\n",
    "        sorting_ele.click()\n",
    "        time.sleep(0.2)\n",
    "        option = self.wait_element(By.XPATH, '//div[contains(text(),\"Insurer (A - Z)\")]', 20)\n",
    "        option.click()\n",
    "\n",
    "        # clicking on search button\n",
    "        self.wait_element(By.CSS_SELECTOR, '.btn-search', 20).click()\n",
    "\n",
    "        # clicking on `i agree`\n",
    "        self.wait_element(By.CSS_SELECTOR, '[id=\"iUnderstant\"]', 20).click()\n",
    "    \n",
    "    def scroll_container(self):\n",
    "        products_container = self.wait_element(By.CSS_SELECTOR, '#result_container', 20)\n",
    "        \n",
    "        # Initial scroll position\n",
    "        last_height = driver.execute_script(\"return arguments[0].scrollHeight\", products_container)\n",
    "        scroll_attempts = 0\n",
    "        max_attempts = 10  # Limit tries to prevent infinite loops\n",
    "\n",
    "        while scroll_attempts < max_attempts:\n",
    "            # Scroll down to bottom\n",
    "            scroll_script = \"arguments[0].scrollTo(0, arguments[0].scrollHeight);\"\n",
    "            driver.execute_script(scroll_script, products_container)\n",
    "            \n",
    "            # Wait to load page\n",
    "            time.sleep(0.2)\n",
    "            \n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", products_container)\n",
    "            \n",
    "            # If heights are the same, we've reached the bottom or no new content is loading\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "                \n",
    "            last_height = new_height\n",
    "            scroll_attempts += 1\n",
    "\n",
    "        print(f\"Finished scrolling after {scroll_attempts} attempts\")\n",
    "\n",
    "    def check_if_provider_is_required(self, provider_name):\n",
    "        # print(\"checking provider: \", provider_name)\n",
    "        all_providers = [\n",
    "            \"China Life Insurance (Singapore) Pte. Ltd.\",\n",
    "            \"China Taiping Insurance (Singapore) Pte. Ltd.\",\n",
    "            \"Income Insurance Limited\",\n",
    "            \"Manulife (Singapore) Pte. Ltd.\",\n",
    "            \"Singapore Life Ltd.\",\n",
    "            \"Tokio Marine Life Insurance Singapore Ltd\"\n",
    "        ]\n",
    "        \n",
    "        return provider_name in all_providers\n",
    "    \n",
    "    def check_if_product_is_required(self, product_name):\n",
    "        # print(\"checking product: \", product_name)\n",
    "        all_products = [\n",
    "            \"China Life Term Guardian\",\n",
    "            \"China Life Term Guardian Plus\",\n",
    "            \"i-Protect\",\n",
    "            \"i-Protect (Renewable)\",\n",
    "            \"Star Term Protect\",\n",
    "            \"TermLife Solitaire\",\n",
    "            \"ManuProtect Term (II) (with TPD Plus) (Level & Convertible)\",\n",
    "            \"ManuProtect Term (II) (with TPD Plus) (Renewable & Convertible)\",\n",
    "            \"ManuProtect Term (II) (with TPD Plus & CI) (Level & Convertible)\",\n",
    "            \"ManuProtect Term (II) (with TPD Plus & CI) (Renewable & Convertible)\",\n",
    "            \"Singlife Elite Term II\",\n",
    "            \"Singlife Simple Term\",\n",
    "            \"TM Term Assure (II)(Level & Convertible)\",\n",
    "            \"TM Term Assure (II)(Renewable & Convertible)\"\n",
    "        ]\n",
    "        return product_name in all_products\n",
    "    \n",
    "    def get_driver_with_retry(self, retries=3, delay=2):\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                driver.get(\"https://www.comparefirst.sg/wap/homeEvent.action\")\n",
    "                time.sleep(delay)\n",
    "                self.wait_element(By.XPATH, '//label[contains(text(),\"Whole Life products\")]', 20)\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "                time.sleep(delay)\n",
    "        raise Exception(\"Failed to load page after several attempts.\")\n",
    "\n",
    "    def scrape_products(self):\n",
    "        global data\n",
    "\n",
    "        try:\n",
    "            # getting total products available to scrape it looks like `showing 5 of 25`\n",
    "            total_products_text = self.wait_element(By.CSS_SELECTOR, '[id=\"Whole_LN_Count\"]', 20).text\n",
    "            total_products = int(total_products_text.split(\" \")[-1])\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        index = 0\n",
    "\n",
    "        while index < total_products:\n",
    "            checkbox = self.wait_element(By.CSS_SELECTOR, '[id=\"Whole_LC\"]', 20)\n",
    "            print(\"Checkbox selected before clicking:\", checkbox.is_selected())\n",
    "            if checkbox.is_selected():\n",
    "                checkbox.click()\n",
    "                time.sleep(2)\n",
    "            print(\"Checkbox selected after clicking:\", checkbox.is_selected())\n",
    "            print(f\"scraping data for product {index + 1} of {total_products}\")\n",
    "            # scroll products box to load all products\n",
    "            self.scroll_container()\n",
    "\n",
    "            # getting all `view details` buttons\n",
    "            try:\n",
    "                view_details_buttons = self.wait_element(By.CSS_SELECTOR, '[class=\"search_detail\"]', 20, wait_all=True)\n",
    "                # Filter out nodes with visible parent LI element\n",
    "                visible_buttons = []\n",
    "\n",
    "                for button in view_details_buttons:\n",
    "                    try:\n",
    "                        parent_li = button.find_element(By.XPATH, './ancestor::li')\n",
    "                        if parent_li.is_displayed():  # Check display\n",
    "                            visible_buttons.append(button)\n",
    "                    except:\n",
    "                        continue # If li is not found, skip it.\n",
    "            except Exception as e:\n",
    "                print(\"No products found\")\n",
    "                break\n",
    "\n",
    "            # first checking if provider is what we need to scrape\n",
    "            providers = self.wait_element(By.CSS_SELECTOR, '.result_content_inner h3', 20, wait_all=True)\n",
    "            provider_element = providers[index]\n",
    "            provider = provider_element.get_attribute('textContent')\n",
    "            # print(\"innerHTML:\", provider_element.get_attribute('innerHTML'))\n",
    "            # print(\"textContent:\", provider_element.get_attribute('textContent'))\n",
    "            # provider = self.wait_element(By.CSS_SELECTOR, '.result_content_inner h3', 20, wait_all=True)[index].text\n",
    "            print(\"checking provider nè: \", provider)\n",
    "            products = self.wait_element(By.CSS_SELECTOR, '[id=\"sProdName\"]', 20, wait_all=True)\n",
    "            products_element = products[index]\n",
    "            product = products_element.get_attribute('textContent')\n",
    "\n",
    "            print(\"checking provider nè: \", product)\n",
    "\n",
    "            # Skip if provider or product is not required\n",
    "            if not self.check_if_provider_is_required(provider):\n",
    "                print(f\"Skipping product {index + 1} - Provider: {provider}, Product: {product}\")\n",
    "                index += 1\n",
    "                continue\n",
    "\n",
    "            current_product_button = visible_buttons[index]\n",
    "            self.js_click(current_product_button)\n",
    "\n",
    "            # extracting data\n",
    "            try:\n",
    "                provider = self.wait_element(By.CSS_SELECTOR, '.product_details_right h3', 20).text\n",
    "            except:\n",
    "                print(f\"Failed to extract provider details for product {index + 1}\")\n",
    "                driver.back()\n",
    "                time.sleep(1)\n",
    "                index += 1\n",
    "                continue\n",
    "\n",
    "            # Skip if provider is not required (double-check)\n",
    "            if not self.check_if_provider_is_required(provider):\n",
    "                print(f\"Skipping product {index + 1} - Provider: {provider}\")\n",
    "                driver.back()\n",
    "                time.sleep(1)\n",
    "                index += 1\n",
    "                continue\n",
    "\n",
    "            product = self.wait_element(By.CSS_SELECTOR, '.prod-desc', 20).text\n",
    "            print(f\"scraping data for {product} product\")\n",
    "            \n",
    "            coverage_term = self.wait_element(By.CSS_SELECTOR, '.policy-term', 20, wait_all=True)[0].text\n",
    "            subtitle = self.wait_element(By.CSS_SELECTOR, '.Subtitle', 20, wait_all=True)[0].text\n",
    "\n",
    "\n",
    "            elements = self.wait_element(By.CSS_SELECTOR, '.pay-period', 20, wait_all=True)\n",
    "            premium_term = \"\"\n",
    "            for el in elements:\n",
    "                text = el.text.strip()\n",
    "                if text:\n",
    "                    premium_term = text\n",
    "                    break\n",
    "            elements = self.wait_element(By.CSS_SELECTOR, '.annual-premium',20, wait_all=True)\n",
    "\n",
    "            main_plan_annual_premium = \"\"\n",
    "            for el in elements:\n",
    "                text = el.text.strip()\n",
    "                if text:\n",
    "                    main_plan_annual_premium = text\n",
    "                    break\n",
    "            elements = self.wait_element(By.CSS_SELECTOR, '.tot-premium',20, wait_all=True)\n",
    "\n",
    "            tot_premium = \"\"\n",
    "            for el in elements:\n",
    "                text = el.text.strip()\n",
    "                if text:\n",
    "                    print(\"tot_premium text: \", text)\n",
    "                    tot_premium = self.parse_currency(text)\n",
    "                    break\n",
    "\n",
    "            ##Click on the \"Death Benefit\" tab\n",
    "            death_tab = self.wait_element(By.CSS_SELECTOR, 'ul.wl_tabs li a[href=\"#wl_tab1\"]', timeout=10)\n",
    "            if death_tab:\n",
    "                death_tab.click()\n",
    "            else:\n",
    "                print(\"Death Benefit tab not found\")\n",
    "                \n",
    "            tab_content = self.wait_element(By.CSS_SELECTOR, '#wl_tab1', timeout=10)\n",
    "            if not tab_content:\n",
    "                print(\"Death Benefit tab content not found\")\n",
    "            else:\n",
    "                #Get data from tables in tab\n",
    "                db_years = [el.text for el in tab_content.find_elements(By.CSS_SELECTOR, \".tab-content-table3\")]\n",
    "                db_guaranteed = [el.text for el in tab_content.find_elements(By.CSS_SELECTOR, \".tab-content-table1.tab-content-table4\")]\n",
    "                db_lower_rate = [el.text for el in tab_content.find_elements(By.CSS_SELECTOR, \".tab-content-table1[class*='lr']\")]\n",
    "                db_higher_rate = [el.text for el in tab_content.find_elements(By.CSS_SELECTOR, \".tab-content-table1[class*='hr']\")]\n",
    "\n",
    "            # Click tab \"Surrender Value\"\n",
    "            tab2 = self.wait_element(By.CSS_SELECTOR, 'ul.wl_tabs li a[href=\"#wl_tab2\"]', timeout=10)\n",
    "            if tab2:\n",
    "                tab2.click()\n",
    "            else:\n",
    "                print(\"Surrender Value tab not found\")\n",
    "            \n",
    "            # Wait for tab2 content to display\n",
    "            tab2_content = self.wait_element(By.CSS_SELECTOR, '#wl_tab2', timeout=10)\n",
    "            if not tab2_content:\n",
    "                print(\"Tab2 content not found\")\n",
    "                return\n",
    "            # Get data in tab2\n",
    "            sv_years = [el.text for el in tab2_content.find_elements(By.CSS_SELECTOR, \".tab-content-table3\")]\n",
    "            sv_guaranteed = [el.text for el in tab2_content.find_elements(By.CSS_SELECTOR, \".tab-content-table1.tab-content-table4\")]\n",
    "            sv_lower_rate = [el.text for el in tab2_content.find_elements(By.CSS_SELECTOR, \".tab-content-table1[class*='lr']\")]\n",
    "            sv_higher_rate = [el.text for el in tab2_content.find_elements(By.CSS_SELECTOR, \".tab-content-table1[class*='hr']\")]\n",
    "\n",
    "\n",
    "                        \n",
    "            product_rows = []\n",
    "            num_years = min(len(db_years), len(db_guaranteed), len(db_lower_rate), len(db_higher_rate),\n",
    "                len(sv_years), len(sv_guaranteed), len(sv_lower_rate), len(sv_higher_rate))\n",
    "\n",
    "            for i in range(num_years):\n",
    "                row = {\n",
    "                    \"product_type\": \"Whole Life products\",\n",
    "                    \"provider\": provider,\n",
    "                    \"product\": product,\n",
    "                    \"Subtitle\": subtitle,\n",
    "                    \"Age\": self.search_data[\"age\"],\n",
    "                    \"Gender\": self.search_data[\"gender\"],\n",
    "                    \"Smoker\": self.search_data[\"smoker\"],\n",
    "                    \"Critical Illness benefit\": self.search_data[\"critical_illness\"],\n",
    "                    \"Premium Type\": \"Annual\",\n",
    "                    \"Sum Assured\": self.search_data[\"sum_assured\"],\n",
    "                    \"Coverage Term\": coverage_term,\n",
    "                    \"Premium Term\": premium_term,\n",
    "                    \"Total Premium\": tot_premium,\n",
    "                    \"Main Plan Annual Premium\": main_plan_annual_premium,\n",
    "                    \"DB_Year\": db_years[i],\n",
    "                    \"DB_Guaranteed\": db_guaranteed[i],\n",
    "                    \"DB_Lower Rate\": db_lower_rate[i],\n",
    "                    \"DB_Higher Rate\": db_higher_rate[i],\n",
    "                    \"SV_Year\": sv_years[i],\n",
    "                    \"SV_Guaranteed\": sv_guaranteed[i],\n",
    "                    \"SV_Lower Rate\": sv_lower_rate[i],\n",
    "                    \"SV_Higher Rate\": sv_higher_rate[i],\n",
    "                }\n",
    "                row = self.calculate_ratios(row)\n",
    "                product_rows.append(row)\n",
    "            # Print the rows\n",
    "                        \n",
    "            data.extend(product_rows)\n",
    "            self.save_to_excel()\n",
    "\n",
    "            # go back\n",
    "            driver.back()\n",
    "            time.sleep(1)\n",
    "\n",
    "            index += 1\n",
    "            if index >= total_products:\n",
    "                break\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def save_to_excel(self):\n",
    "        global data\n",
    "\n",
    "        # print(\"innerHTML data:\", data)\n",
    "        df = pd.DataFrame(data)\n",
    "        file_name = \"Whole_Life_Products.xlsx\"\n",
    "        try:\n",
    "            df.to_excel(file_name, index=False)\n",
    "            print(f\"Excel file created: {file_name}\")\n",
    "        except PermissionError:\n",
    "            # Handle the case where the file is open or locked\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            backup_file_name = f\"Whole_Life_Products_{timestamp}.xlsx\"\n",
    "            df.to_excel(backup_file_name, index=False)\n",
    "            print(f\"Original file is locked. Saved as: {backup_file_name}\")\n",
    "\n",
    "    def js_click(self, element):\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    def calculate_ratios(self, row):\n",
    "        try:\n",
    "            total_premium = float(row[\"Total Premium\"])\n",
    "        except:\n",
    "            return row  # Nếu không thể chuyển đổi thì bỏ qua\n",
    "\n",
    "        for prefix in [\"DB\", \"SV\"]:\n",
    "            for key_suffix, ratio_key in [\n",
    "                (\"Guaranteed\", \"Guaranteed_Ratio\"),\n",
    "                (\"Lower Rate\", \"LowerRate_Ratio\"),\n",
    "                (\"Higher Rate\", \"UpperRate_Ratio\"),\n",
    "            ]:\n",
    "                key = f\"{prefix}_{key_suffix}\"\n",
    "                ratio_column = f\"{key}_{ratio_key}\"\n",
    "                try:\n",
    "                    value = self.parse_currency(row[key])\n",
    "                    print(f\"Calculating ratio for \", value)\n",
    "                    row[ratio_column] = round(value / total_premium, 2)\n",
    "                except:\n",
    "                    row[ratio_column] = None\n",
    "\n",
    "        return row\n",
    "    \n",
    "    def parse_currency(self, text):\n",
    "        cleaned = re.sub(r\"[^\\d.]\", \"\", text)\n",
    "        return float(cleaned) if cleaned else 0.0\n",
    "\n",
    "    def wait_element(self, using, css_code, timeout, wait_all=False):\n",
    "        if wait_all:\n",
    "            WebDriverWait(driver, timeout).until(\n",
    "                EC.presence_of_all_elements_located((using, css_code)))\n",
    "            elements = driver.find_elements(using, css_code)\n",
    "            return elements\n",
    "        else:\n",
    "            try:\n",
    "                element = WebDriverWait(driver, timeout).until(\n",
    "                    EC.presence_of_element_located((using, css_code))\n",
    "                )\n",
    "                return element\n",
    "            except Exception as e:\n",
    "                return None\n",
    "\n",
    "product_type=\"Whole Life products\"\n",
    "\n",
    "\n",
    "term_life_data=get_term_data()\n",
    "\n",
    "\n",
    "count = 0\n",
    "while count < len(term_life_data):\n",
    "    data_combination = term_life_data[count]\n",
    "    print(data_combination)\n",
    "    bot = TermLifeAutomation(search_data=data_combination)\n",
    "    bot.do_search()\n",
    "    output = bot.scrape_products()\n",
    "\n",
    "    if output is not None:\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "        print(\"increasing count to +1 coz in last iteration there was gateway problem. \")\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "        count += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
